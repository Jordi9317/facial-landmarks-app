# app.py
"""
Aplicaci√≥n Streamlit para detecci√≥n de landmarks faciales.
"""

import streamlit as st
from PIL import Image
from src.detector import FaceLandmarkDetector
from src.visualizacion import FaceLandmarkVisualizer
from src.expresiones import FacialExpressionAnalyzer
from src.exportacion import (
    export_landmarks_json,
    export_landmarks_csv,
    export_expressions_json,
    create_download_link
)
from src.utils import pil_to_cv2, cv2_to_pil, resize_image
from src.config import TOTAL_LANDMARKS

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Detector de Landmarks Faciales",
    layout="wide"
)

# T√≠tulo y descripci√≥n
st.title("Detector de Landmarks Faciales")
st.markdown("""
Esta aplicaci√≥n detecta **478 puntos clave** en rostros humanos usando MediaPipe Face Mesh.
Sub√≠ una imagen con un rostro y mir√° la magia de la visi√≥n por computadora.
""")

# Sidebar con informaci√≥n y controles
with st.sidebar:
    st.header("Informaci√≥n")
    st.markdown("""
    ### ¬øQu√© son los Landmarks?
    Son puntos de referencia que mapean:
    - 478 puntos precisos por rostro usando MediaPipe
    - Ojos, cejas, nariz, boca, contorno facial
    - Coordenadas 3D (x, y, z) normalizadas
    - Alta precisi√≥n para an√°lisis facial detallado
    """)

    st.divider()

    # Controles de visualizaci√≥n
    st.header("üé® Estilo de Visualizaci√≥n")
    visualization_style = st.selectbox(
        "Eleg√≠ el estilo de dibujo:",
        ["Puntos Simples", "Malla Conectada", "Contornos Principales", "Heatmap"],
        help="Diferentes formas de mostrar los landmarks detectados"
    )

    st.header("üìä An√°lisis de Expresiones")
    analyze_expressions = st.checkbox(
        "Analizar expresiones faciales",
        help="Calcula m√©tricas como apertura de boca, ojos y inclinaci√≥n de cabeza"
    )

    st.header("üíæ Exportaci√≥n de Datos")
    export_format = st.selectbox(
        "Formato de exportaci√≥n:",
        ["JSON", "CSV"],
        help="Formato para descargar las coordenadas de landmarks"
    )

    st.divider()
    st.caption("Desarrollado en el Laboratorio 2 - IFTS24")

# Uploader de imagen
uploaded_file = st.file_uploader(
    "üì§ Sub√≠ una imagen con un rostro",
    type=["jpg", "jpeg", "png"],
    help="Formatos aceptados: JPG, JPEG, PNG"
)

if uploaded_file is not None:
    # Cargar imagen
    imagen_original = Image.open(uploaded_file)

    # Convertir a formato OpenCV
    imagen_cv2 = pil_to_cv2(imagen_original)

    # Redimensionar si es muy grande
    imagen_cv2 = resize_image(imagen_cv2, max_width=800)

    # Columnas para mostrar antes/despu√©s
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("üñºÔ∏è Imagen Original")
        st.image(cv2_to_pil(imagen_cv2), use_column_width=True)

    # Detectar landmarks
    with st.spinner("üîç Detectando landmarks faciales..."):
        detector = FaceLandmarkDetector()
        imagen_procesada, landmarks, info = detector.detect(imagen_cv2)
        detector.close()

    # Aplicar estilo de visualizaci√≥n seleccionado
    if info["deteccion_exitosa"] and landmarks:
        visualizer = FaceLandmarkVisualizer()

        # Tomar el primer rostro para visualizaci√≥n
        primer_rostro = landmarks[0] if isinstance(landmarks, list) else landmarks

        if visualization_style == "Puntos Simples":
            imagen_visualizada = visualizer.draw_points_only(imagen_cv2, primer_rostro)
        elif visualization_style == "Malla Conectada":
            imagen_visualizada = visualizer.draw_mesh_tesselation(imagen_cv2, primer_rostro)
        elif visualization_style == "Contornos Principales":
            imagen_visualizada = visualizer.draw_contours_only(imagen_cv2, primer_rostro)
        elif visualization_style == "Heatmap":
            imagen_visualizada = visualizer.create_heatmap_overlay(imagen_cv2, primer_rostro)
        else:
            imagen_visualizada = imagen_procesada  # Fallback
    else:
        imagen_visualizada = imagen_procesada

    with col2:
        st.subheader(f"üé® Landmarks - {visualization_style}")
        st.image(cv2_to_pil(imagen_visualizada), use_column_width=True)

    # Mostrar informaci√≥n de detecci√≥n
    st.divider()

    if info["deteccion_exitosa"]:
        st.success("‚úÖ Detecci√≥n exitosa")

        # M√©tricas principales
        metric_col1, metric_col2, metric_col3 = st.columns(3)

        with metric_col1:
            st.metric("üë§ Rostros detectados", info["rostros_detectados"])

        with metric_col2:
            st.metric("üìç Landmarks detectados", f"{info['total_landmarks']}/{TOTAL_LANDMARKS}")

        with metric_col3:
            porcentaje = (info['total_landmarks'] / TOTAL_LANDMARKS) * 100
            st.metric("üéØ Precisi√≥n", f"{porcentaje:.1f}%")

        # An√°lisis de expresiones (si est√° habilitado)
        if analyze_expressions and landmarks:
            st.header("üòä An√°lisis de Expresiones")

            analyzer = FacialExpressionAnalyzer()
            # Tomar el primer rostro para an√°lisis de expresiones
            primer_rostro = landmarks[0] if isinstance(landmarks, list) and landmarks else None
            if primer_rostro:
                expresion_data = analyzer.analizar_expresion_basica(primer_rostro, imagen_cv2.shape[0], imagen_cv2.shape[1])

            # Mostrar m√©tricas de expresi√≥n
            exp_col1, exp_col2, exp_col3 = st.columns(3)

            with exp_col1:
                st.metric("üëÑ Apertura Boca", f"{expresion_data['apertura_boca']:.3f}")

            with exp_col2:
                st.metric("üëÅÔ∏è Apertura Ojos", f"{expresion_data['apertura_ojos']['promedio']:.3f}")

            with exp_col3:
                st.metric("üìê Inclinaci√≥n Cabeza", f"{expresion_data['inclinacion_cabeza']:.3f}¬∞")

            # Clasificaci√≥n de expresi√≥n
            st.info(f"**Expresi√≥n detectada:** {expresion_data['expresion_detectada'].replace('_', ' ').title()}")

            # Exportar datos de expresiones
            expressions_json, expr_filename = export_expressions_json(expresion_data)
            st.download_button(
                label="üìä Descargar An√°lisis de Expresiones (JSON)",
                data=expressions_json,
                file_name=expr_filename,
                mime="application/json",
                key="download_expressions"
            )

        # Exportaci√≥n de landmarks
        st.header("üíæ Exportar Datos")

        if export_format == "JSON":
            landmarks_data, filename = export_landmarks_json(landmarks, imagen_cv2.shape[0], imagen_cv2.shape[1])
            mime_type = "application/json"
        else:  # CSV
            landmarks_data, filename = export_landmarks_csv(landmarks, imagen_cv2.shape[0], imagen_cv2.shape[1])
            mime_type = "text/csv"

        st.download_button(
            label=f"üìç Descargar Landmarks ({export_format})",
            data=landmarks_data,
            file_name=filename,
            mime=mime_type,
            key=f"download_landmarks_{export_format.lower()}"
        )

    else:
        st.error("‚ùå No se detect√≥ ning√∫n rostro en la imagen")
        st.info("""
        **üí° Consejos para mejorar la detecci√≥n:**
        - Asegurate de que el rostro est√© bien iluminado
        - El rostro debe estar mirando hacia la c√°mara
        - Prob√° con una imagen de mayor calidad
        - Evit√° √°ngulos extremos o rostros parcialmente ocultos
        """)

else:
    # Mensaje de bienvenida
    st.info("üì§ Sub√≠ una imagen para comenzar la detecci√≥n")

    # Informaci√≥n sobre estilos de visualizaci√≥n
    st.header("üé® Estilos de Visualizaci√≥n Disponibles")

    viz_col1, viz_col2 = st.columns(2)

    with viz_col1:
        st.subheader("Puntos Simples")
        st.write("Visualizaci√≥n b√°sica con puntos verdes")
        st.subheader("Malla Conectada")
        st.write("Puntos conectados formando una malla 3D")

    with viz_col2:
        st.subheader("Contornos Principales")
        st.write("Solo ojos, boca y contorno facial")
        st.subheader("Heatmap")
        st.write("Mapa de calor de densidad de puntos")

    # Informaci√≥n sobre funcionalidades
    st.markdown("### üéØ Funcionalidades Disponibles")

    col_demo1, col_demo2 = st.columns(2)

    with col_demo1:
        st.markdown("**üîç Detecci√≥n Avanzada**")
        st.write("‚Ä¢ Hasta 5 rostros simult√°neamente")
        st.write("‚Ä¢ 478 landmarks por rostro")
        st.write("‚Ä¢ Precisi√≥n MediaPipe Face Mesh")

        st.markdown("**üé® Visualizaci√≥n M√∫ltiple**")
        st.write("‚Ä¢ Puntos simples")
        st.write("‚Ä¢ Malla conectada")
        st.write("‚Ä¢ Contornos principales")
        st.write("‚Ä¢ Mapa de calor")

    with col_demo2:
        st.markdown("**üòä An√°lisis de Expresiones**")
        st.write("‚Ä¢ Apertura de boca")
        st.write("‚Ä¢ Apertura de ojos")
        st.write("‚Ä¢ Inclinaci√≥n de cabeza")

        st.markdown("**üíæ Exportaci√≥n de Datos**")
        st.write("‚Ä¢ Formato JSON completo")
        st.write("‚Ä¢ CSV tabular")
        st.write("‚Ä¢ Metadatos incluidos")